name: Deploy to AWS EKS

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

on:
  push:
    branches: [main]
    paths:
      - "lib/**"
      - "services/**"
      - "k8s/**"
      - "web/**"
      - "scripts/**"
      - "config/**"
      - ".github/workflows/**"
      - "k8s/**"
      - ".dockerignore"
  workflow_dispatch:
    inputs:
      environment:
        description: "Deployment environment"
        required: true
        default: "production"
        type: choice
        options:
          - development
          - staging
          - production

env:
  AWS_REGION: us-east-1
  EKS_CLUSTER_NAME: cloudtolocalllm-eks
  DOCKER_REGISTRY: cloudtolocalllm

jobs:
  build_base_image:
    name: Build Base Image (Fedora)
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check for changes to Dockerfile.base
        uses: dorny/paths-filter@v3
        id: changes
        with:
          filters: |
            dockerfile:
              - 'config/docker/Dockerfile.base'

      - name: Login to Docker Hub
        if: steps.changes.outputs.dockerfile == 'true'
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Set up Docker Buildx
        if: steps.changes.outputs.dockerfile == 'true'
        uses: docker/setup-buildx-action@v3

      - name: Build and push Base Image
        if: steps.changes.outputs.dockerfile == 'true'
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./config/docker/Dockerfile.base
          push: true
          tags: ${{ env.DOCKER_REGISTRY }}/base:latest
          cache-from: type=registry,ref=${{ env.DOCKER_REGISTRY }}/base:latest
          cache-to: type=inline

  build_builder_image:
    name: Build Builder Image
    needs: build_base_image
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check for changes to Dockerfiles
        uses: dorny/paths-filter@v3
        id: changes
        with:
          filters: |
            dockerfile:
              - 'config/docker/Dockerfile.base-builder'
              - 'config/docker/Dockerfile.base'

      - name: Login to Docker Hub
        if: steps.changes.outputs.dockerfile == 'true'
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Set up Docker Buildx
        if: steps.changes.outputs.dockerfile == 'true'
        uses: docker/setup-buildx-action@v3

      - name: Build and push Builder Image
        if: steps.changes.outputs.dockerfile == 'true'
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./config/docker/Dockerfile.base-builder
          push: true
          tags: ${{ env.DOCKER_REGISTRY }}/base-builder:latest
          cache-from: type=registry,ref=${{ env.DOCKER_REGISTRY }}/base-builder:latest
          cache-to: type=inline

  build_artifacts:
    name: Compile Artifacts
    needs: build_builder_image
    runs-on: ubuntu-latest
    container:
      image: cloudtolocalllm/base-builder:latest
      # Run container as root to allow actions/checkout to work
      options: --user root
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Fix permissions
        run: |
          chown -R cloudtolocalllm:cloudtolocalllm .

      - name: Build Flutter Web
        run: |
          su cloudtolocalllm -c "flutter config --no-analytics"
          su cloudtolocalllm -c "flutter pub get"
          su cloudtolocalllm -c "flutter build web --release --no-tree-shake-icons"
        working-directory: ./web

      - name: Install API Dependencies
        run: |
          su cloudtolocalllm -c "npm ci && npm prune --production"
        working-directory: ./services/api-backend

      - name: Install Streaming Dependencies
        run: |
          su cloudtolocalllm -c "npm ci && npm prune --production"
        working-directory: ./services/streaming-proxy

      - name: Upload Web Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: web-build
          path: build/web

      - name: Upload API Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: api-build
          path: services/api-backend

      - name: Upload Streaming Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: streaming-build
          path: services/streaming-proxy

  build_images:
    name: Build Runtime Images
    needs: build_artifacts
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download Web Artifacts
        uses: actions/download-artifact@v4
        with:
          name: web-build
          path: build/web

      - name: Download API Artifacts
        uses: actions/download-artifact@v4
        with:
          name: api-build
          path: services/api-backend

      - name: Download Streaming Artifacts
        uses: actions/download-artifact@v4
        with:
          name: streaming-build
          path: services/streaming-proxy

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build and push web app image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./web/Dockerfile
          push: true
          tags: |
            ${{ env.DOCKER_REGISTRY }}/web:${{ github.sha }}
            ${{ env.DOCKER_REGISTRY }}/web:latest
          cache-from: type=registry,ref=${{ env.DOCKER_REGISTRY }}/web:latest
          cache-to: type=inline

      - name: Build and push API backend image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./services/api-backend/Dockerfile.prod
          push: true
          tags: |
            ${{ env.DOCKER_REGISTRY }}/api-backend:${{ github.sha }}
            ${{ env.DOCKER_REGISTRY }}/api-backend:latest
          cache-from: type=registry,ref=${{ env.DOCKER_REGISTRY }}/api-backend:latest
          cache-to: type=inline

      - name: Build and push Streaming Proxy image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./services/streaming-proxy/Dockerfile.prod
          push: true
          tags: |
            ${{ env.DOCKER_REGISTRY }}/streaming-proxy:${{ github.sha }}
            ${{ env.DOCKER_REGISTRY }}/streaming-proxy:latest
          cache-from: type=registry,ref=${{ env.DOCKER_REGISTRY }}/streaming-proxy:latest
          cache-to: type=inline

      - name: Build and push PostgreSQL image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./services/postgres/Dockerfile
          push: true
          tags: |
            ${{ env.DOCKER_REGISTRY }}/postgres:${{ github.sha }}
            ${{ env.DOCKER_REGISTRY }}/postgres:latest
          cache-from: type=registry,ref=${{ env.DOCKER_REGISTRY }}/postgres:latest
          cache-to: type=inline

      - name: Verify Web Container Startup
        run: |
          echo "Verifying Web container startup..."
          docker run -d --name test-web ${{ env.DOCKER_REGISTRY }}/web:${{ github.sha }}
          sleep 5
          if [ "$(docker inspect -f '{{.State.Running}}' test-web)" = "true" ]; then
            echo "Web container is running."
            docker stop test-web
            docker rm test-web
          else
            echo "Web container failed to start."
            docker logs test-web
            docker rm test-web
            exit 1
          fi

      - name: Verify Postgres Container Startup
        run: |
          echo "Verifying Postgres container startup..."
          # Postgres needs a password to start
          docker run -d --name test-postgres -e POSTGRES_PASSWORD=testpassword -e POSTGRES_USER=cloud_admin -e POSTGRES_DB=cloudtolocalllm ${{ env.DOCKER_REGISTRY }}/postgres:${{ github.sha }}
          sleep 10
          if [ "$(docker inspect -f '{{.State.Running}}' test-postgres)" = "true" ]; then
            echo "Postgres container is running."
            docker stop test-postgres
            docker rm test-postgres
          else
            echo "Postgres container failed to start."
            docker logs test-postgres
            docker rm test-postgres
            exit 1
            docker rm test-postgres
            exit 1
          fi

      - name: Build and push Deployer image
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./config/docker/Dockerfile.deployer
          push: true
          tags: |
            ${{ env.DOCKER_REGISTRY }}/deployer:${{ github.sha }}
            ${{ env.DOCKER_REGISTRY }}/deployer:latest
          cache-from: type=registry,ref=${{ env.DOCKER_REGISTRY }}/deployer:latest
          cache-to: type=inline

  deploy:
    name: Deploy to EKS
    needs: build_images
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write # Required for OIDC token exchange

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::422017356244:role/github-actions-role
          aws-region: ${{ env.AWS_REGION }}
          role-session-name: github-actions-eks-deployment-${{ github.run_id }}
          role-duration-seconds: 3600

      - name: Set kubectl credentials without kubeconfig
        id: set-kubectl
        run: |
          # Get cluster endpoint and CA data
          CLUSTER_INFO=$(aws eks describe-cluster --name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }} --query "cluster.{endpoint: endpoint, certificateAuthorityData: certificateAuthority.data}" --output json)
          KUBE_ENDPOINT=$(echo $CLUSTER_INFO | jq -r .endpoint)
          KUBE_CA_DATA=$(echo $CLUSTER_INFO | jq -r .certificateAuthorityData)

          echo "KUBE_ENDPOINT=$KUBE_ENDPOINT" >> $GITHUB_ENV
          echo "KUBE_CA_DATA=$KUBE_CA_DATA" >> $GITHUB_ENV

          # Get authentication token
          KUBE_TOKEN=$(aws eks get-token --cluster-name ${{ env.EKS_CLUSTER_NAME }} --region ${{ env.AWS_REGION }} --query "status.token" --output text)
          echo "KUBE_TOKEN=$KUBE_TOKEN" >> $GITHUB_ENV

          # Build a temporary kubeconfig file
          cat <<EOF > /tmp/kubeconfig
          apiVersion: v1
          kind: Config
          clusters:
          - name: eks-cluster
            cluster:
              server: $KUBE_ENDPOINT
              certificate-authority-data: $KUBE_CA_DATA
          contexts:
          - name: eks-context
            context:
              cluster: eks-cluster
              user: eks-user
          current-context: eks-context
          users:
          - name: eks-user
            user:
              token: $KUBE_TOKEN
          EOF
          export KUBECONFIG=/tmp/kubeconfig
          echo "KUBECONFIG=/tmp/kubeconfig" >> $GITHUB_ENV

      - name: Determine environment and namespace
        run: |
          # Determine environment from workflow input or default to production
          ENVIRONMENT="${{ github.event.inputs.environment }}"
          if [ -z "$ENVIRONMENT" ]; then
            ENVIRONMENT="production"
          fi
          echo "ENVIRONMENT=$ENVIRONMENT" >> $GITHUB_ENV

          # Set namespace based on environment
          case $ENVIRONMENT in
            development) NAMESPACE="cloudtolocalllm-dev" ;;
            staging)     NAMESPACE="cloudtolocalllm-staging" ;;
            production)  NAMESPACE="cloudtolocalllm" ;;
            *) echo "Invalid environment: $ENVIRONMENT"; exit 1 ;;
          esac
          echo "NAMESPACE=$NAMESPACE" >> $GITHUB_ENV

      - name: Determine environment and namespace
        run: |
          # Determine environment from workflow input or default to production
          ENVIRONMENT="${{ github.event.inputs.environment }}"
          if [ -z "$ENVIRONMENT" ]; then
            ENVIRONMENT="production"
          fi

          echo "ENVIRONMENT=$ENVIRONMENT" >> $GITHUB_ENV

          # Set namespace based on environment
          case $ENVIRONMENT in
            development)
              NAMESPACE="cloudtolocalllm-dev"
              ;;
            staging)
              NAMESPACE="cloudtolocalllm-staging"
              ;;
            production)
              NAMESPACE="cloudtolocalllm"
              ;;
            *)
              echo "Invalid environment: $ENVIRONMENT"
              exit 1
              ;;
          esac

          echo "NAMESPACE=$NAMESPACE" >> $GITHUB_ENV
          echo "Deploying to environment: $ENVIRONMENT"
          echo "Using namespace: $NAMESPACE"

      - name: Create namespace if not exists
        run: |
          kubectl create namespace ${{ env.NAMESPACE }} --dry-run=client -o yaml | kubectl apply -f -

      - name: Clean up existing deployments
        run: |
          echo "Deleting existing deployments to allow immutable field updates..."
          kubectl delete deployment web api-backend streaming-proxy -n ${{ env.NAMESPACE }} --ignore-not-found=true
          kubectl delete statefulset postgres -n ${{ env.NAMESPACE }} --ignore-not-found=true

      - name: Apply base Kubernetes manifests
        env:
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
          JWT_SECRET: ${{ secrets.JWT_SECRET }}
          AUTH0_CLIENT_SECRET: ${{ secrets.AUTH0_CLIENT_SECRET }}
          STRIPE_TEST_SECRET_KEY: ${{ secrets.STRIPE_TEST_SECRET_KEY }}
          STRIPE_TEST_PUBLISHABLE_KEY: ${{ secrets.STRIPE_TEST_PUBLISHABLE_KEY }}
          STRIPE_TEST_WEBHOOK_SECRET: ${{ secrets.STRIPE_TEST_WEBHOOK_SECRET }}
          STRIPE_LIVE_SECRET_KEY: ${{ secrets.STRIPE_LIVE_SECRET_KEY }}
          STRIPE_LIVE_PUBLISHABLE_KEY: ${{ secrets.STRIPE_LIVE_PUBLISHABLE_KEY }}
          STRIPE_LIVE_WEBHOOK_SECRET: ${{ secrets.STRIPE_LIVE_WEBHOOK_SECRET }}
          SENTRY_DSN: ${{ secrets.SENTRY_DSN }}
        run: |
          echo "Applying base Kubernetes manifests..."

          # Create secrets dynamically from environment variables
          # Using environment variables avoids quoting issues and logging secrets
          kubectl create secret generic cloudtolocalllm-secrets \
            --namespace ${{ env.NAMESPACE }} \
            --from-literal=postgres-user=cloud_admin \
            --from-literal=postgres-password="$POSTGRES_PASSWORD" \
            --from-literal=jwt-secret="$JWT_SECRET" \
            --from-literal=auth0-domain='dev-v2f2p008x3dr74ww.us.auth0.com' \
            --from-literal=auth0-audience='https://api.cloudtolocalllm.online' \
            --from-literal=auth0-client-id='FuXPnevXpp311CdYHGsbNZe9t3D8Ts7A' \
            --from-literal=auth0-client-secret="$AUTH0_CLIENT_SECRET" \
            --from-literal=stripe-test-secret-key="$STRIPE_TEST_SECRET_KEY" \
            --from-literal=stripe-test-publishable-key="$STRIPE_TEST_PUBLISHABLE_KEY" \
            --from-literal=stripe-test-webhook-secret="$STRIPE_TEST_WEBHOOK_SECRET" \
            --from-literal=stripe-live-secret-key="$STRIPE_LIVE_SECRET_KEY" \
            --from-literal=stripe-live-publishable-key="$STRIPE_LIVE_PUBLISHABLE_KEY" \
            --from-literal=stripe-live-webhook-secret="$STRIPE_LIVE_WEBHOOK_SECRET" \
            --from-literal=sentry-dsn="$SENTRY_DSN" \
            --dry-run=client -o yaml | kubectl apply -f -

          # Apply base manifests in order
          kubectl apply -f k8s/namespace.yaml
          kubectl apply -f k8s/configmap.yaml -n ${{ env.NAMESPACE }}
          # secrets.yaml is no longer applied from file
          kubectl apply -f k8s/rbac.yaml -n ${{ env.NAMESPACE }}
          kubectl apply -f k8s/network-policies.yaml -n ${{ env.NAMESPACE }}

          echo "Base manifests applied successfully"

      - name: Apply Deployer RBAC
        run: |
          kubectl apply -f k8s/deployer-rbac.yaml

      - name: Run In-Cluster Deployment Job
        env:
          WEB_IMAGE: ${{ env.DOCKER_REGISTRY }}/web:${{ github.sha }}
          API_IMAGE: ${{ env.DOCKER_REGISTRY }}/api-backend:${{ github.sha }}
          STREAMING_IMAGE: ${{ env.DOCKER_REGISTRY }}/streaming-proxy:${{ github.sha }}
          POSTGRES_IMAGE: ${{ env.DOCKER_REGISTRY }}/postgres:${{ github.sha }}
        run: |
          echo "Preparing deployment job..."

          # Delete previous job if exists
          kubectl delete job deploy-job -n ${{ env.NAMESPACE }} --ignore-not-found=true

          # Substitute env vars in job template
          # We use envsubst to replace ${VAR} with actual values
          envsubst < k8s/deployer-job.yaml | sed "s|cloudtolocalllm/deployer:latest|${{ env.DOCKER_REGISTRY }}/deployer:${{ github.sha }}|g" > deploy-job-final.yaml

          echo "Applying deployment job..."
          kubectl apply -f deploy-job-final.yaml

          echo "Waiting for deployment job to start..."
          kubectl wait --for=condition=ready pod -l job-name=deploy-job -n ${{ env.NAMESPACE }} --timeout=60s || true

          echo "Streaming deployment logs..."
          # Get the pod name
          POD_NAME=$(kubectl get pods -l job-name=deploy-job -n ${{ env.NAMESPACE }} -o jsonpath='{.items[0].metadata.name}')

          # Stream logs and wait for completion
          kubectl logs -f $POD_NAME -n ${{ env.NAMESPACE }}

          # Check job exit status
          echo "Checking job status..."
          kubectl wait --for=condition=complete job/deploy-job -n ${{ env.NAMESPACE }} --timeout=600s

  validation:
    name: Validate Deployment
    needs: deploy
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write # Required for OIDC token exchange

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::422017356244:role/github-actions-role
          aws-region: ${{ env.AWS_REGION }}
          role-session-name: github-actions-eks-validation-${{ github.run_id }}
          role-duration-seconds: 3600

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig \
            --name ${{ env.EKS_CLUSTER_NAME }} \
            --region ${{ env.AWS_REGION }}

      - name: Determine environment and namespace
        run: |
          # Determine environment from workflow input or default to production
          ENVIRONMENT="${{ github.event.inputs.environment }}"
          if [ -z "$ENVIRONMENT" ]; then
            ENVIRONMENT="production"
          fi

          # Set namespace based on environment
          case $ENVIRONMENT in
            development)
              NAMESPACE="cloudtolocalllm-dev"
              ;;
            staging)
              NAMESPACE="cloudtolocalllm-staging"
              ;;
            production)
              NAMESPACE="cloudtolocalllm"
              ;;
          esac

          echo "ENVIRONMENT=$ENVIRONMENT" >> $GITHUB_ENV
          echo "NAMESPACE=$NAMESPACE" >> $GITHUB_ENV

      - name: Verify deployment health
        run: |
          echo "Checking pod status..."
          kubectl get pods -n ${{ env.NAMESPACE }}

          echo ""
          echo "Checking service status..."
          kubectl get svc -n ${{ env.NAMESPACE }}

          echo ""
          echo "Checking ingress status..."
          kubectl get ingress -n ${{ env.NAMESPACE }}

      - name: Setup Cloudflare DNS Integration
        if: env.ENVIRONMENT == 'production'
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "Setting up Cloudflare DNS integration..."

          echo "Waiting for Ingress Load Balancer endpoint..."
          NLB_ENDPOINT=""
          for i in {1..60}; do
            NLB_ENDPOINT=$(kubectl get ingress -n ${{ env.NAMESPACE }} -o jsonpath='{.items[0].status.loadBalancer.ingress[0].hostname}')
            if [ -n "$NLB_ENDPOINT" ]; then
              echo "Found hostname: $NLB_ENDPOINT"
              break
            fi
            
            NLB_ENDPOINT=$(kubectl get ingress -n ${{ env.NAMESPACE }} -o jsonpath='{.items[0].status.loadBalancer.ingress[0].ip}')
            if [ -n "$NLB_ENDPOINT" ]; then
              echo "Found IP: $NLB_ENDPOINT"
              break
            fi
            
            echo "Attempt $i/60: Ingress endpoint not ready yet..."
            sleep 10
          done

          if [ -z "$NLB_ENDPOINT" ]; then
             echo "Error: Could not retrieve Ingress Load Balancer endpoint after waiting."
             echo "Debug: Ingress status:"
             kubectl get ingress -n ${{ env.NAMESPACE }} -o yaml
             exit 1
          fi

          echo "NLB Endpoint: $NLB_ENDPOINT"

          # Get Cloudflare Zone ID
          ZONE_RESPONSE=$(curl -s -X GET "https://api.cloudflare.com/client/v4/zones?name=cloudtolocalllm.online" \
            -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
            -H "Content-Type: application/json")

          ZONE_ID=$(echo "$ZONE_RESPONSE" | jq -r '.result[0].id')
          echo "Cloudflare Zone ID: $ZONE_ID"

          # Update DNS records for each domain
          for DOMAIN in "cloudtolocalllm.online" "app.cloudtolocalllm.online" "api.cloudtolocalllm.online" "auth.cloudtolocalllm.online"; do
            echo "Updating DNS record for: $DOMAIN"
            
            # Get existing record
            RECORD_RESPONSE=$(curl -s -X GET "https://api.cloudflare.com/client/v4/zones/$ZONE_ID/dns_records?name=$DOMAIN" \
              -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
              -H "Content-Type: application/json")
            
            RECORD_COUNT=$(echo "$RECORD_RESPONSE" | jq '.result | length')
            
            if [ "$RECORD_COUNT" -gt 0 ]; then
              RECORD_ID=$(echo "$RECORD_RESPONSE" | jq -r '.result[0].id')
              RECORD_TYPE=$(echo "$RECORD_RESPONSE" | jq -r '.result[0].type')
              
              # Update existing record
              curl -s -X PUT "https://api.cloudflare.com/client/v4/zones/$ZONE_ID/dns_records/$RECORD_ID" \
                -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
                -H "Content-Type: application/json" \
                -d "{
                  \"type\": \"$RECORD_TYPE\",
                  \"name\": \"$DOMAIN\",
                  \"content\": \"$NLB_ENDPOINT\",
                  \"ttl\": 300,
                  \"proxied\": true
                }" > /dev/null
              
              echo "  ✓ Updated DNS record for $DOMAIN"
            else
              # Create new A record
              curl -s -X POST "https://api.cloudflare.com/client/v4/zones/$ZONE_ID/dns_records" \
                -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
                -H "Content-Type: application/json" \
                -d "{
                  \"type\": \"A\",
                  \"name\": \"$DOMAIN\",
                  \"content\": \"$NLB_ENDPOINT\",
                  \"ttl\": 300,
                  \"proxied\": true
                }" > /dev/null
              
              echo "  ✓ Created DNS record for $DOMAIN"
            fi
          done

          # Configure SSL/TLS settings
          echo "Configuring SSL/TLS settings..."

          # Set SSL mode to "Full"
          curl -s -X PATCH "https://api.cloudflare.com/client/v4/zones/$ZONE_ID/settings/ssl" \
            -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
            -H "Content-Type: application/json" \
            -d '{"value": "full"}' > /dev/null

          # Enable "Always Use HTTPS"
          curl -s -X PATCH "https://api.cloudflare.com/client/v4/zones/$ZONE_ID/settings/always_use_https" \
            -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
            -H "Content-Type: application/json" \
            -d '{"value": "on"}' > /dev/null

          # Purge cache
          echo "Purging Cloudflare cache..."
          curl -s -X POST "https://api.cloudflare.com/client/v4/zones/$ZONE_ID/purge_cache" \
            -H "Authorization: Bearer $CLOUDFLARE_API_TOKEN" \
            -H "Content-Type: application/json" \
            -d '{"purge_everything": true}' > /dev/null

          echo "✓ Cloudflare DNS integration complete"

      - name: Verify application accessibility
        run: |
          if [ "${{ env.ENVIRONMENT }}" == "production" ]; then
            TARGET_URL="https://app.cloudtolocalllm.online/health"
            echo "Verifying production endpoint: $TARGET_URL"
          else
            # For non-production, try to get Ingress endpoint
             NLB_ENDPOINT=$(kubectl get ingress -n ${{ env.NAMESPACE }} -o jsonpath='{.items[0].status.loadBalancer.ingress[0].hostname}')
             if [ -z "$NLB_ENDPOINT" ]; then
                NLB_ENDPOINT=$(kubectl get ingress -n ${{ env.NAMESPACE }} -o jsonpath='{.items[0].status.loadBalancer.ingress[0].ip}')
             fi
             # We use http here as certs won't match
             TARGET_URL="http://$NLB_ENDPOINT/health"
             echo "Verifying non-production endpoint: $TARGET_URL"
          fi

          # Wait for endpoint to be ready
          for i in {1..30}; do
            if curl -f -s "$TARGET_URL" > /dev/null 2>&1; then
              echo "✓ Application is accessible at $TARGET_URL"
              exit 0
            fi
            echo "Attempt $i/30: Waiting for application to be ready..."
            sleep 10
          done

          echo "✗ Application did not become accessible within timeout"
          exit 1

      - name: Track deployment history
        run: |
          echo "Recording deployment history..."

          # Get deployment revisions
          echo ""
          echo "Web Deployment History:"
          kubectl rollout history deployment/web -n ${{ env.NAMESPACE }}

          echo ""
          echo "API Backend Deployment History:"
          kubectl rollout history deployment/api-backend -n ${{ env.NAMESPACE }}

          echo ""
          echo "Streaming Proxy Deployment History:"
          kubectl rollout history deployment/streaming-proxy -n ${{ env.NAMESPACE }}

      - name: Deployment successful
        run: |
          echo "✓ Deployment to AWS EKS completed successfully"
          echo ""
          echo "Deployment Summary:"
          echo "- Environment: ${{ env.ENVIRONMENT }}"
          echo "- Cluster: ${{ env.EKS_CLUSTER_NAME }}"
          echo "- Region: ${{ env.AWS_REGION }}"
          echo "- Namespace: ${{ env.NAMESPACE }}"
          echo "- Web Image: ${{ env.DOCKER_REGISTRY }}/web:${{ github.sha }}"
          echo "- API Backend Image: ${{ env.DOCKER_REGISTRY }}/api-backend:${{ github.sha }}"
          echo "- Streaming Proxy Image: ${{ env.DOCKER_REGISTRY }}/streaming-proxy:${{ github.sha }}"
          echo "- Commit: ${{ github.sha }}"
          echo "- Branch: ${{ github.ref }}"

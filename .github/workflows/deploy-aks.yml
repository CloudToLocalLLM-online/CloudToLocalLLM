name: Deploy to Azure AKS

on:
  push:
    branches:
      - main
    paths:
      - "k8s/**"
      - ".github/workflows/deploy-aks.yml"
      - "services/**"
      - "web/**"
      - "lib/**"
      - "pubspec.**"
      - "config/docker/**"
      - "scripts/**"
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  AZURE_RESOURCE_GROUP: cloudtolocalllm-rg
  AZURE_CLUSTER_NAME: cloudtolocalllm-aks
  ACR_NAME: cloudtolocalllm
  # DOCKER_REGISTRY will be set dynamically to the ACR login server
  DOCKER_REGISTRY: ""

jobs:
  # Job to detect changes in specific paths
  changes:
    runs-on: ubuntu-latest
    outputs:
      base: ${{ steps.filter.outputs.base }}
      postgres: ${{ steps.filter.outputs.postgres }}
      web: ${{ steps.filter.outputs.web }}
      api: ${{ steps.filter.outputs.api }}
      proxy: ${{ steps.filter.outputs.proxy }}
    steps:
      - uses: actions/checkout@v4
      - uses: dorny/paths-filter@v2
        id: filter
        with:
          filters: |
            base:
              - 'config/docker/Dockerfile.base'
              - '.github/workflows/deploy-aks.yml'
            postgres:
              - 'config/docker/Dockerfile.postgres'
              - 'config/docker/postgres-init.sh'
              - 'config/docker/postgres-entrypoint.sh'
              - '.github/workflows/deploy-aks.yml'
            web:
              - 'web/**'
              - 'lib/**'
              - 'pubspec.**'
              - 'config/docker/Dockerfile.base'
              - '.github/workflows/deploy-aks.yml'
            api:
              - 'services/api-backend/**'
              - 'config/docker/Dockerfile.base'
              - '.github/workflows/deploy-aks.yml'
            proxy:
              - 'services/streaming-proxy/**'
              - 'config/docker/Dockerfile.base'
              - '.github/workflows/deploy-aks.yml'

  build_base:
    needs: changes
    if: ${{ !cancelled() && needs.changes.outputs.base == 'true' }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
      - name: Setup ACR
        run: |
          # Create ACR if not exists
          az acr create --resource-group ${{ env.AZURE_RESOURCE_GROUP }} --name ${{ env.ACR_NAME }} --sku Basic --admin-enabled true
          # Get Login Server
          echo "DOCKER_REGISTRY=$(az acr show --name ${{ env.ACR_NAME }} --query loginServer --output tsv)" >> $GITHUB_ENV
      - name: Docker Login to ACR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.DOCKER_REGISTRY }}
          username: ${{ secrets.AZURE_CLIENT_ID }}
          password: ${{ secrets.AZURE_CLIENT_SECRET }}
      - uses: docker/setup-buildx-action@v3
      - uses: docker/build-push-action@v5
        with:
          context: .
          file: config/docker/Dockerfile.base
          push: true
          tags: ${{ env.DOCKER_REGISTRY }}/base:${{ github.sha }}
          cache-from: type=registry,ref=${{ env.DOCKER_REGISTRY }}/base:latest
          cache-to: type=inline

  build_postgres:
    needs: [changes, build_base]
    if: ${{ !cancelled() && (needs.changes.outputs.postgres == 'true' || needs.changes.outputs.base == 'true') && (needs.build_base.result == 'success' || needs.build_base.result == 'skipped') }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
      - name: Get ACR Login Server
        run: echo "DOCKER_REGISTRY=$(az acr show --name ${{ env.ACR_NAME }} --query loginServer --output tsv)" >> $GITHUB_ENV
      - name: Docker Login to ACR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.DOCKER_REGISTRY }}
          username: ${{ secrets.AZURE_CLIENT_ID }}
          password: ${{ secrets.AZURE_CLIENT_SECRET }}
      - uses: docker/setup-buildx-action@v3
      - uses: docker/build-push-action@v5
        with:
          context: .
          file: config/docker/Dockerfile.postgres
          push: true
          tags: ${{ env.DOCKER_REGISTRY }}/postgres:${{ github.sha }}
          build-args: |
            BASE_REGISTRY=${{ env.DOCKER_REGISTRY }}
          cache-from: type=registry,ref=${{ env.DOCKER_REGISTRY }}/postgres:latest
          cache-to: type=inline

  build_web:
    needs: [changes, build_base]
    if: ${{ !cancelled() && (needs.changes.outputs.web == 'true' || needs.changes.outputs.base == 'true') && (needs.build_base.result == 'success' || needs.build_base.result == 'skipped') }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
      - name: Get ACR Login Server
        run: echo "DOCKER_REGISTRY=$(az acr show --name ${{ env.ACR_NAME }} --query loginServer --output tsv)" >> $GITHUB_ENV
      - name: Docker Login to ACR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.DOCKER_REGISTRY }}
          username: ${{ secrets.AZURE_CLIENT_ID }}
          password: ${{ secrets.AZURE_CLIENT_SECRET }}
      - uses: docker/setup-buildx-action@v3
      - uses: subosito/flutter-action@v2
        with:
          channel: "stable"
          cache: true
      - run: flutter pub get && flutter build web --release --no-tree-shake-icons
      - name: Debug - List web build
        run: ls -R build/web || echo "build/web not found"
      - uses: docker/build-push-action@v5
        with:
          context: .
          file: web/Dockerfile
          push: true
          tags: ${{ env.DOCKER_REGISTRY }}/web:${{ github.sha }}
          build-args: |
            BASE_REGISTRY=${{ env.DOCKER_REGISTRY }}
          cache-from: type=registry,ref=${{ env.DOCKER_REGISTRY }}/web:latest
          cache-to: type=inline

  build_api:
    needs: [changes, build_base]
    if: ${{ !cancelled() && (needs.changes.outputs.api == 'true' || needs.changes.outputs.base == 'true') && (needs.build_base.result == 'success' || needs.build_base.result == 'skipped') }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
      - name: Get ACR Login Server
        run: echo "DOCKER_REGISTRY=$(az acr show --name ${{ env.ACR_NAME }} --query loginServer --output tsv)" >> $GITHUB_ENV
      - name: Docker Login to ACR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.DOCKER_REGISTRY }}
          username: ${{ secrets.AZURE_CLIENT_ID }}
          password: ${{ secrets.AZURE_CLIENT_SECRET }}
      - uses: docker/setup-buildx-action@v3
      - uses: docker/build-push-action@v5
        with:
          context: services/api-backend
          file: services/api-backend/Dockerfile
          push: true
          tags: ${{ env.DOCKER_REGISTRY }}/api-backend:${{ github.sha }}
          build-args: |
            BASE_REGISTRY=${{ env.DOCKER_REGISTRY }}
          cache-from: type=registry,ref=${{ env.DOCKER_REGISTRY }}/api-backend:latest
          cache-to: type=inline

  build_proxy:
    needs: [changes, build_base]
    if: ${{ !cancelled() && (needs.changes.outputs.proxy == 'true' || needs.changes.outputs.base == 'true') && (needs.build_base.result == 'success' || needs.build_base.result == 'skipped') }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}
      - name: Get ACR Login Server
        run: echo "DOCKER_REGISTRY=$(az acr show --name ${{ env.ACR_NAME }} --query loginServer --output tsv)" >> $GITHUB_ENV
      - name: Docker Login to ACR
        uses: docker/login-action@v3
        with:
          registry: ${{ env.DOCKER_REGISTRY }}
          username: ${{ secrets.AZURE_CLIENT_ID }}
          password: ${{ secrets.AZURE_CLIENT_SECRET }}
      - uses: docker/setup-buildx-action@v3
      - uses: docker/build-push-action@v5
        with:
          context: services/streaming-proxy
          file: services/streaming-proxy/Dockerfile
          push: true
          tags: ${{ env.DOCKER_REGISTRY }}/streaming-proxy:${{ github.sha }}
          build-args: |
            BASE_REGISTRY=${{ env.DOCKER_REGISTRY }}
          cache-from: type=registry,ref=${{ env.DOCKER_REGISTRY }}/streaming-proxy:latest
          cache-to: type=inline

  deploy_infrastructure:
    # Run if any build job ran OR if k8s files changed
    needs:
      [changes, build_base, build_postgres, build_web, build_api, build_proxy]
    if: |
      !cancelled() && 
      (needs.build_base.result == 'success' || needs.build_base.result == 'skipped') &&
      (needs.build_postgres.result == 'success' || needs.build_postgres.result == 'skipped') &&
      (needs.build_web.result == 'success' || needs.build_web.result == 'skipped') &&
      (needs.build_api.result == 'success' || needs.build_api.result == 'skipped') &&
      (needs.build_proxy.result == 'success' || needs.build_proxy.result == 'skipped')
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Get AKS credentials
        uses: azure/aks-set-context@v3
        with:
          resource-group: ${{ env.AZURE_RESOURCE_GROUP }}
          cluster-name: ${{ env.AZURE_CLUSTER_NAME }}

      - name: Setup ACR Integration
        run: |
          # Get Login Server (ACR assumed to exist or created in build steps)
          echo "DOCKER_REGISTRY=$(az acr show --name ${{ env.ACR_NAME }} --query loginServer --output tsv)" >> $GITHUB_ENV

      - name: Ensure Namespace Exists
        run: |
          kubectl create namespace cloudtolocalllm --dry-run=client -o yaml | kubectl apply -f -

      - name: Setup Azure Key Vault and Secrets Store CSI Driver
        run: |
          # Install the Secrets Store CSI Driver
          helm repo add secrets-store-csi-driver https://kubernetes-sigs.github.io/secrets-store-csi-driver/charts
          helm install csi-secrets-store secrets-store-csi-driver/secrets-store-csi-driver --namespace kube-system

          # Install the Azure Key Vault Provider
          helm repo add azure-keyvault-provider https://raw.githubusercontent.com/Azure/secrets-store-csi-driver-provider-azure/main/charts
          helm install akv-provider azure-keyvault-provider/csi-driver-provider-azure --namespace kube-system

      - name: Create SecretProviderClass
        uses: azure/k8s-create-secret@v1
        with:
          namespace: cloudtolocalllm
          secret-name: cloudtolocalllm-secrets-from-akv
          secret-type: Opaque
          secret-provider-class: |
            apiVersion: secrets-store.csi.x-k8s.io/v1
            kind: SecretProviderClass
            metadata:
              name: azure-kvname-user-msi
            spec:
              provider: azure
              parameters:
                usePodIdentity: "false"
                useVMManagedIdentity: "true"
                userAssignedIdentityID: "" # Set this to the client ID of the user-assigned managed identity if you use one.
                keyvaultName: ${{ secrets.AZURE_KEY_VAULT_NAME }}
                objects:  |
                  array:
                    - |
                      objectName: POSTGRES-PASSWORD
                      objectType: secret
                    - |
                      objectName: JWT-SECRET
                      objectType: secret
                    - |
                      objectName: AUTH0-CLIENT-SECRET
                      objectType: secret
                    - |
                      objectName: STRIPE-TEST-SECRET-KEY
                      objectType: secret
                    - |
                      objectName: CLOUDFLARE-TUNNEL-TOKEN
                      objectType: secret
                tenantId: ${{ secrets.AZURE_TENANT_ID }}

      - name: Deploy Manifests
        run: |
          # Replace image registry in manifests
          sed -i "s|cloudtolocalllm/postgres:latest|${{ env.DOCKER_REGISTRY }}/postgres:${{ github.sha }}|g" k8s/postgres-statefulset.yaml
          sed -i "s|cloudtolocalllm/web:latest|${{ env.DOCKER_REGISTRY }}/web:${{ github.sha }}|g" k8s/web-deployment.yaml
          sed -i "s|cloudtolocalllm/api-backend:latest|${{ env.DOCKER_REGISTRY }}/api-backend:${{ github.sha }}|g" k8s/api-backend-deployment.yaml
          sed -i "s|cloudtolocalllm/streaming-proxy:latest|${{ env.DOCKER_REGISTRY }}/streaming-proxy:${{ github.sha }}|g" k8s/streaming-proxy-deployment.yaml

          # Apply RBAC and ConfigMaps first
          kubectl apply -f k8s/rbac.yaml
          kubectl apply -f k8s/configmap.yaml
          kubectl apply -f k8s/streaming-proxy-configmap.yaml

          # Apply Infrastructure
          kubectl apply -f k8s/postgres-statefulset.yaml
          kubectl apply -f k8s/cloudflared.yaml

          # Apply Services
          kubectl apply -f k8s/web-deployment.yaml
          kubectl apply -f k8s/api-backend-deployment.yaml
          kubectl apply -f k8s/streaming-proxy-deployment.yaml

          # Force roll out restart to pick up latest images and secrets
          # Force delete postgres pod to ensure it picks up new spec (fix for stuck CrashLoopBackOff)
          kubectl delete pod postgres-0 -n cloudtolocalllm --force --grace-period=0 || true
          kubectl rollout restart statefulset/postgres -n cloudtolocalllm
          kubectl rollout restart deployment/web -n cloudtolocalllm
          kubectl rollout restart deployment/api-backend -n cloudtolocalllm
          kubectl rollout restart deployment/streaming-proxy -n cloudtolocalllm
          kubectl rollout restart deployment/cloudflared -n cloudtolocalllm

          # Wait for Rollout to Complete (with Fail Fast)
          chmod +x scripts/watch_rollout.sh
          ./scripts/watch_rollout.sh cloudtolocalllm statefulset postgres
          ./scripts/watch_rollout.sh cloudtolocalllm deployment web
          ./scripts/watch_rollout.sh cloudtolocalllm deployment api-backend
          ./scripts/watch_rollout.sh cloudtolocalllm deployment streaming-proxy

      - name: Verify Cloudflare Tunnel
        run: |
          echo "Waiting for Cloudflare Tunnel to be ready..."
          kubectl wait --for=condition=ready pod -l app=cloudflared -n cloudtolocalllm --timeout=300s

          echo "Checking Tunnel Logs..."
          # Retry checking logs for connection success message (increased to 24 attempts = 2 minutes)
          for i in {1..24}; do
            if kubectl logs -l app=cloudflared -n cloudtolocalllm | grep -q "Registered tunnel connection"; then
              echo "Tunnel connection verified!"
              exit 0
            fi
            echo "Attempt $i: Tunnel not yet registered, waiting 5s..."
            sleep 5
          done
          echo "Tunnel verification failed. Dumping logs:"
          kubectl logs -l app=cloudflared -n cloudtolocalllm
          exit 1

      - name: Update Cloudflare DNS
        env:
          CLOUDFLARE_DNS_TOKEN: ${{ secrets.CLOUDFLARE_DNS_TOKEN }}
          CLOUDFLARE_TUNNEL_TOKEN: ${{ secrets.CLOUDFLARE_TUNNEL_TOKEN }}
        run: |
          set -x
          # --- Update Cloudflare DNS Records ---
          ZONE_NAME="cloudtolocalllm.online"
          TUNNEL_ID="62da6c19-947b-4bf6-acad-100a73de4e0d"
          TUNNEL_CNAME="$TUNNEL_ID.cfargotunnel.com"
          TUNNEL_TOKEN="${{ secrets.CLOUDFLARE_TUNNEL_TOKEN }}"

          if [ -z "$TUNNEL_TOKEN" ]; then
            echo "Error: CLOUDFLARE_TUNNEL_TOKEN secret is empty"
            exit 1
          fi

          echo "Fetching Zone ID for $ZONE_NAME..."
          ZONE_ID=$(curl -s -X GET "https://api.cloudflare.com/client/v4/zones?name=$ZONE_NAME" \
            -H "Authorization: Bearer $CLOUDFLARE_DNS_TOKEN" \
            -H "Content-Type: application/json" | jq -r '.result[0].id')

          if [ "$ZONE_ID" == "null" ] || [ -z "$ZONE_ID" ]; then
            echo "Error: Could not find Zone ID for $ZONE_NAME"
            exit 1
          fi

          # Function to update or create CNAME record
          update_dns_record() {
            local NAME=$1
            local CONTENT=$2
            local PROXIED=$3
            
            echo "Updating DNS record: $NAME -> $CONTENT (Proxied: $PROXIED)"
            
            # Check if record exists
            local RECORD_JSON=$(curl -s -X GET "https://api.cloudflare.com/client/v4/zones/$ZONE_ID/dns_records?type=CNAME&name=$NAME" \
              -H "Authorization: Bearer $CLOUDFLARE_DNS_TOKEN" \
              -H "Content-Type: application/json")
            
            local RECORD_ID=$(echo "$RECORD_JSON" | jq -r '.result[0].id')
            
            if [ "$RECORD_ID" != "null" ] && [ -n "$RECORD_ID" ]; then
               # Update existing
               local RESPONSE=$(curl -s -X PUT "https://api.cloudflare.com/client/v4/zones/$ZONE_ID/dns_records/$RECORD_ID" \
                 -H "Authorization: Bearer $CLOUDFLARE_DNS_TOKEN" \
                 -H "Content-Type: application/json" \
                 --data "{\"type\":\"CNAME\",\"name\":\"$NAME\",\"content\":\"$CONTENT\",\"proxied\":$PROXIED,\"ttl\":1}")
            else
               # Create new
               local RESPONSE=$(curl -s -X POST "https://api.cloudflare.com/client/v4/zones/$ZONE_ID/dns_records" \
                 -H "Authorization: Bearer $CLOUDFLARE_DNS_TOKEN" \
                 -H "Content-Type: application/json" \
                 --data "{\"type\":\"CNAME\",\"name\":\"$NAME\",\"content\":\"$CONTENT\",\"proxied\":$PROXIED,\"ttl\":1}")
            fi
          }

          # Update Records
          update_dns_record "app" "$TUNNEL_CNAME" true
          update_dns_record "api" "$TUNNEL_CNAME" true
          update_dns_record "@" "$TUNNEL_CNAME" true

      - name: Check Health Endpoint
        run: |
          echo "Waiting for DNS propagation and service health..."
          # Retry loop for 2 minutes
          for i in {1..24}; do
            if curl -s -f https://app.cloudtolocalllm.online/health; then
              echo "Health check passed!"
              exit 0
            fi
            echo "Attempt $i: Health check failed, waiting 5s..."
            sleep 5
          done
          echo "Health check failed after 2 minutes. Dumping api-backend logs:"
          kubectl get pods -n cloudtolocalllm
          kubectl logs postgres-0 -n cloudtolocalllm --tail=50
          kubectl describe pod postgres-0 -n cloudtolocalllm
          kubectl logs -l app=api-backend -n cloudtolocalllm --tail=100
          kubectl describe pod -l app=api-backend -n cloudtolocalllm
          exit 1

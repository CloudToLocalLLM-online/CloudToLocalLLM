name: Deploy to Azure AKS

permissions:
  id-token: write

on:
  repository_dispatch: # Trigger via repository_dispatch (accepts dynamic types like cloud-deploy-4.12.12)
  workflow_dispatch:
    inputs:
      version_tag:
        description: "Version tag to deploy (optional, uses version.json if not provided)"
        required: false
        type: string

# Gemini AI integration: Use Gemini for AI-assisted deployment analysis
# Model: gemini-2.0-flash
# Cloud AI: Enabled for deployment planning and issue detection

concurrency:
  group: cloud-deployment # All cloud deployments share same concurrency group
  cancel-in-progress: true # Cancel old deployment when new version arrives

env:
  AZURE_RESOURCE_GROUP: cloudtolocalllm-rg
  AZURE_CLUSTER_NAME: cloudtolocalllm-aks
  ACR_NAME: imrightguycloudtolocalllm
  # DOCKER_REGISTRY will be set dynamically to the ACR login server
  DOCKER_REGISTRY: ""

jobs:
  # Extract version info from branch or tag
  extract_version:
    runs-on: ubuntu-latest
    outputs:
      app_version: ${{ steps.parse.outputs.app_version }}
      commit_sha: ${{ steps.parse.outputs.commit_sha }}
      deploy_source: ${{ steps.parse.outputs.deploy_source }}
    steps:
      - uses: actions/checkout@v4

      - name: Parse Version
        id: parse
        run: |
          # Determine source: branch, tag, or manual
          if [ "${{ github.event_name }}" = "workflow_dispatch" ] && [ -n "${{ inputs.version_tag }}" ]; then
            # Manual trigger with tag
            TAG_NAME="${{ inputs.version_tag }}"
            APP_VERSION=$(echo "$TAG_NAME" | sed -E 's/([0-9]+\.[0-9]+\.[0-9]+)-.*/\1/')
            COMMIT_SHA=$(echo "$TAG_NAME" | sed -E 's/.*-([a-f0-9]+)$/\1/')
            SOURCE="manual-tag"
          elif [[ "${{ github.ref }}" == refs/tags/* ]]; then
            # Tag push
            TAG_NAME="${GITHUB_REF#refs/tags/}"
            APP_VERSION=$(echo "$TAG_NAME" | sed -E 's/([0-9]+\.[0-9]+\.[0-9]+)-.*/\1/')
            COMMIT_SHA=$(echo "$TAG_NAME" | sed -E 's/.*-([a-f0-9]+)$/\1/')
            SOURCE="tag"
          else
            # Branch push (cloud branch)
            APP_VERSION=$(jq -r '.version' assets/version.json | tr '+' '-')
            COMMIT_SHA=$(git rev-parse --short HEAD)
            SOURCE="cloud-branch"
          fi

          echo "app_version=$APP_VERSION" >> $GITHUB_OUTPUT
          echo "commit_sha=$COMMIT_SHA" >> $GITHUB_OUTPUT
          echo "deploy_source=$SOURCE" >> $GITHUB_OUTPUT

          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "Cloud Deployment for v$APP_VERSION"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "Version: $APP_VERSION"
          echo "Commit: $COMMIT_SHA"
          echo "Source: $SOURCE"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

  # Job to detect changes in specific paths (compare against last cloud tag)
  changes:
    needs: extract_version
    runs-on: ubuntu-latest
    outputs:
      base: ${{ steps.detect.outputs.base }}
      postgres: ${{ steps.detect.outputs.postgres }}
      web: ${{ steps.detect.outputs.web }}
      api: ${{ steps.detect.outputs.api }}
      proxy: ${{ steps.detect.outputs.proxy }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Detect Service Changes
        id: detect
        run: |
          # Find the previous cloud tag
          PREV_TAG=$(git tag -l "*-cloud-*" --sort=-version:refname | head -2 | tail -1 || echo "")

          if [ -z "$PREV_TAG" ]; then
            echo "No previous tag found, building all services"
            echo "base=true" >> $GITHUB_OUTPUT
            echo "postgres=true" >> $GITHUB_OUTPUT
            echo "web=true" >> $GITHUB_OUTPUT
            echo "api=true" >> $GITHUB_OUTPUT
            echo "proxy=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "Comparing against previous tag: $PREV_TAG"

          # Check for changes in each service (suppress grep output, only capture true/false)
          BASE_CHANGED=$(git diff --name-only $PREV_TAG HEAD | grep -qE '^config/docker/Dockerfile\.base' && echo "true" || echo "false")
          POSTGRES_CHANGED=$(git diff --name-only $PREV_TAG HEAD | grep -qE '^config/docker/(Dockerfile\.postgres|postgres-)' && echo "true" || echo "false")
          WEB_CHANGED=$(git diff --name-only $PREV_TAG HEAD | grep -qE '^(web|lib|pubspec\.)' && echo "true" || echo "false")
          API_CHANGED=$(git diff --name-only $PREV_TAG HEAD | grep -qE '^services/api-backend' && echo "true" || echo "false")
          PROXY_CHANGED=$(git diff --name-only $PREV_TAG HEAD | grep -qE '^services/streaming-proxy' && echo "true" || echo "false")

          echo "base=$BASE_CHANGED" >> $GITHUB_OUTPUT
          echo "postgres=$POSTGRES_CHANGED" >> $GITHUB_OUTPUT
          echo "web=$WEB_CHANGED" >> $GITHUB_OUTPUT
          echo "api=$API_CHANGED" >> $GITHUB_OUTPUT
          echo "proxy=$PROXY_CHANGED" >> $GITHUB_OUTPUT

          echo "Change detection:"
          echo "  Base: $BASE_CHANGED"
          echo "  Postgres: $POSTGRES_CHANGED"
          echo "  Web: $WEB_CHANGED"
          echo "  API: $API_CHANGED"
          echo "  Proxy: $PROXY_CHANGED"

  # Job to setup ACR and retrieve login server
  setup_acr:
    runs-on: ubuntu-latest
    outputs:
      login_server: ${{ steps.acr_setup.outputs.login_server }}
    steps:
      - name: Azure Login
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
      - name: Create Azure Resource Group if not exists
        run: az group create --name ${{ env.AZURE_RESOURCE_GROUP }} --location eastus --query "properties.provisioningState" --output tsv
      - name: Setup ACR
        id: acr_setup
        run: |
          # Create ACR if not exists
          az acr create --resource-group ${{ env.AZURE_RESOURCE_GROUP }} --name ${{ env.ACR_NAME }} --sku Basic --admin-enabled true --query "provisioningState" --output tsv
          # Get Login Server and set as output
          LOGIN_SERVER=$(az acr show --name ${{ env.ACR_NAME }} --query loginServer --output tsv)
          echo "login_server=$LOGIN_SERVER" >> $GITHUB_OUTPUT
          echo "DOCKER_REGISTRY=$LOGIN_SERVER" >> $GITHUB_ENV
      - name: Docker Login to ACR
        run: |
          # Get ACR admin credentials
          ACR_USERNAME=$(az acr credential show --name ${{ env.ACR_NAME }} --query username --output tsv)
          ACR_PASSWORD=$(az acr credential show --name ${{ env.ACR_NAME }} --query passwords[0].value --output tsv)
          # Login to ACR
          echo "$ACR_PASSWORD" | docker login "${{ steps.acr_setup.outputs.login_server }}" --username "$ACR_USERNAME" --password-stdin

  build_base:
    needs: [extract_version, changes, setup_acr]
    if: ${{ !cancelled() && needs.changes.outputs.base == 'true' }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Azure Login
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
      # No need to create RG or ACR here, already done in setup_acr
      - name: Docker Login to ACR
        run: |
          # Get ACR admin credentials
          ACR_USERNAME=$(az acr credential show --name ${{ env.ACR_NAME }} --query username --output tsv)
          ACR_PASSWORD=$(az acr credential show --name ${{ env.ACR_NAME }} --query passwords[0].value --output tsv)
          # Login to ACR
          echo "$ACR_PASSWORD" | docker login "${{ needs.setup_acr.outputs.login_server }}" --username "$ACR_USERNAME" --password-stdin
      - uses: docker/setup-buildx-action@v3
      - uses: docker/build-push-action@v5
        with:
          context: .
          file: config/docker/Dockerfile.base
          push: true
          tags: |
            ${{ needs.setup_acr.outputs.login_server }}/base:${{ needs.extract_version.outputs.app_version }}-base
            ${{ needs.setup_acr.outputs.login_server }}/base:${{ needs.extract_version.outputs.commit_sha }}
            ${{ needs.setup_acr.outputs.login_server }}/base:latest
          cache-from: type=registry,ref=${{ needs.setup_acr.outputs.login_server }}/base:latest
          cache-to: type=inline

  build_postgres:
    needs: [extract_version, changes, setup_acr]
    if: ${{ !cancelled() && (needs.build_base.result == 'success' || needs.build_base.result == 'skipped' || needs.changes.outputs.base != 'true') && needs.changes.outputs.postgres == 'true' }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Azure Login
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
      # No need to create RG or ACR here, already done in setup_acr
      - name: Docker Login to ACR
        run: |
          # Get ACR admin credentials
          ACR_USERNAME=$(az acr credential show --name ${{ env.ACR_NAME }} --query username --output tsv)
          ACR_PASSWORD=$(az acr credential show --name ${{ env.ACR_NAME }} --query passwords[0].value --output tsv)
          # Login to ACR
          echo "$ACR_PASSWORD" | docker login "${{ needs.setup_acr.outputs.login_server }}" --username "$ACR_USERNAME" --password-stdin
      - uses: docker/setup-buildx-action@v3
      - uses: docker/build-push-action@v5
        with:
          context: .
          file: config/docker/Dockerfile.postgres
          push: true
          tags: |
            ${{ needs.setup_acr.outputs.login_server }}/postgres:${{ needs.extract_version.outputs.app_version }}-postgres
            ${{ needs.setup_acr.outputs.login_server }}/postgres:${{ needs.extract_version.outputs.commit_sha }}
            ${{ needs.setup_acr.outputs.login_server }}/postgres:latest
          build-args: |
            BASE_REGISTRY=${{ needs.setup_acr.outputs.login_server }}
          cache-from: type=registry,ref=${{ needs.setup_acr.outputs.login_server }}/postgres:latest
          cache-to: type=inline

  build_web:
    needs: [extract_version, changes, setup_acr]
    if: ${{ !cancelled() && (needs.build_base.result == 'success' || needs.build_base.result == 'skipped' || needs.changes.outputs.base != 'true') && needs.changes.outputs.web == 'true' }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Azure Login
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
      # No need to create RG or ACR here, already done in setup_acr
      - name: Docker Login to ACR
        run: |
          # Get ACR admin credentials
          ACR_USERNAME=$(az acr credential show --name ${{ env.ACR_NAME }} --query username --output tsv)
          ACR_PASSWORD=$(az acr credential show --name ${{ env.ACR_NAME }} --query passwords[0].value --output tsv)
          # Login to ACR
          echo "$ACR_PASSWORD" | docker login "${{ needs.setup_acr.outputs.login_server }}" --username "$ACR_USERNAME" --password-stdin
      - uses: docker/setup-buildx-action@v3
      - name: Check if Flutter is already installed
        id: flutter_check
        run: |
          if command -v flutter >/dev/null 2>&1; then
            FLUTTER_VERSION=$(flutter --version | head -n1 || echo "unknown")
            echo "Flutter is already installed: $FLUTTER_VERSION"
            echo "flutter_installed=true" >> $GITHUB_OUTPUT
          else
            echo "Flutter not found, will install"
            echo "flutter_installed=false" >> $GITHUB_OUTPUT
          fi
      - name: Install Flutter (if needed)
        if: steps.flutter_check.outputs.flutter_installed != 'true'
        uses: subosito/flutter-action@v2
        with:
          channel: "stable"
          cache: true
      - name: Build Flutter Web
        run: |
          flutter pub get
          flutter build web --release --no-tree-shake-icons --base-href / --dart-define=FLUTTER_BUILD_NUMBER=${{ github.sha }}
      - name: Apply Cache Busting to index.html
        run: |
          # Replace placeholder with actual build number (Git SHA)
          sed -i "s|\$FLUTTER_BUILD_NUMBER|${{ github.sha }}|g" build/web/index.html
          # Ensure base href is correctly set for root path
          sed -i "s|\$FLUTTER_BASE_HREF|/|g" build/web/index.html
      - name: Debug - Verify index.html cache busting
        run: |
          echo "Checking if cache-busting was applied:"
          grep "flutter_bootstrap.js" build/web/index.html
      - name: Debug - List web build
        run: ls -R build/web || echo "build/web not found"
      - uses: docker/build-push-action@v5
        with:
          context: .
          file: web/Dockerfile
          push: true
          tags: |
            ${{ needs.setup_acr.outputs.login_server }}/web:${{ needs.extract_version.outputs.app_version }}
            ${{ needs.setup_acr.outputs.login_server }}/web:${{ needs.extract_version.outputs.commit_sha }}
            ${{ needs.setup_acr.outputs.login_server }}/web:latest
          build-args: |
            BASE_REGISTRY=${{ needs.setup_acr.outputs.login_server }}
          cache-from: type=registry,ref=${{ env.DOCKER_REGISTRY }}/web:latest
          cache-to: type=inline

  build_api:
    needs: [extract_version, changes, setup_acr]
    if: ${{ !cancelled() && (needs.build_base.result == 'success' || needs.build_base.result == 'skipped' || needs.changes.outputs.base != 'true') && needs.changes.outputs.api == 'true' }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Azure Login
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
      # No need to create RG or ACR here, already done in setup_acr
      - name: Docker Login to ACR
        run: |
          # Get ACR admin credentials
          ACR_USERNAME=$(az acr credential show --name ${{ env.ACR_NAME }} --query username --output tsv)
          ACR_PASSWORD=$(az acr credential show --name ${{ env.ACR_NAME }} --query passwords[0].value --output tsv)
          # Login to ACR
          echo "$ACR_PASSWORD" | docker login "${{ needs.setup_acr.outputs.login_server }}" --username "$ACR_USERNAME" --password-stdin
      - uses: docker/setup-buildx-action@v3
      - uses: docker/build-push-action@v5
        with:
          context: services/api-backend
          file: services/api-backend/Dockerfile
          push: true
          tags: |
            ${{ needs.setup_acr.outputs.login_server }}/api-backend:${{ needs.extract_version.outputs.app_version }}-api
            ${{ needs.setup_acr.outputs.login_server }}/api-backend:${{ needs.extract_version.outputs.commit_sha }}
            ${{ needs.setup_acr.outputs.login_server }}/api-backend:latest
          build-args: |
            BASE_REGISTRY=${{ needs.setup_acr.outputs.login_server }}
          cache-from: type=registry,ref=${{ env.DOCKER_REGISTRY }}/api-backend:latest
          cache-to: type=inline

  build_proxy:
    needs: [extract_version, changes, setup_acr]
    if: ${{ !cancelled() && (needs.build_base.result == 'success' || needs.build_base.result == 'skipped' || needs.changes.outputs.base != 'true') && needs.changes.outputs.proxy == 'true' }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Azure Login
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
      # No need to create RG or ACR here, already done in setup_acr
      - name: Docker Login to ACR
        run: |
          # Get ACR admin credentials
          ACR_USERNAME=$(az acr credential show --name ${{ env.ACR_NAME }} --query username --output tsv)
          ACR_PASSWORD=$(az acr credential show --name ${{ env.ACR_NAME }} --query passwords[0].value --output tsv)
          # Login to ACR
          echo "$ACR_PASSWORD" | docker login "${{ needs.setup_acr.outputs.login_server }}" --username "$ACR_USERNAME" --password-stdin
      - uses: docker/setup-buildx-action@v3
      - uses: docker/build-push-action@v5
        with:
          context: services/streaming-proxy
          file: services/streaming-proxy/Dockerfile
          push: true
          tags: |
            ${{ needs.setup_acr.outputs.login_server }}/streaming-proxy:${{ needs.extract_version.outputs.app_version }}-proxy
            ${{ needs.setup_acr.outputs.login_server }}/streaming-proxy:${{ needs.extract_version.outputs.commit_sha }}
            ${{ needs.setup_acr.outputs.login_server }}/streaming-proxy:latest
          build-args: |
            BASE_REGISTRY=${{ needs.setup_acr.outputs.login_server }}
          cache-from: type=registry,ref=${{ env.DOCKER_REGISTRY }}/streaming-proxy:latest
          cache-to: type=inline

  deploy_infrastructure:
    permissions:
      id-token: write
    # Run after image builds (or if they were skipped due to unchanged paths)
    needs:
      [
        extract_version,
        changes,
        setup_acr,
        build_base,
        build_postgres,
        build_web,
        build_api,
        build_proxy,
      ]
    if: |
      !cancelled() &&
      (needs.build_base.result == 'success' || needs.build_base.result == 'skipped' || needs.changes.outputs.base != 'true') &&
      (needs.build_postgres.result == 'success' || needs.build_postgres.result == 'skipped' || needs.changes.outputs.postgres != 'true') &&
      (needs.build_web.result == 'success' || needs.build_web.result == 'skipped' || needs.changes.outputs.web != 'true') &&
      (needs.build_api.result == 'success' || needs.build_api.result == 'skipped' || needs.changes.outputs.api != 'true') &&
      (needs.build_proxy.result == 'success' || needs.build_proxy.result == 'skipped' || needs.changes.outputs.proxy != 'true')
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Azure Login
        uses: azure/login@v2
        with:
          client-id: ${{ secrets.AZURE_CLIENT_ID }}
          tenant-id: ${{ secrets.AZURE_TENANT_ID }}
          subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }}
      - name: Bootstrap Azure RG/ACR/Key Vault
        run: |
          chmod +x scripts/bootstrap-azure-infra.sh
          scripts/bootstrap-azure-infra.sh "${{ env.AZURE_RESOURCE_GROUP }}" "eastus" "${{ env.ACR_NAME }}" "${{ secrets.AZURE_KEY_VAULT_NAME }}"
      - name: Create AKS Cluster if not exists
        run: |
          if az aks show --resource-group ${{ env.AZURE_RESOURCE_GROUP }} --name ${{ env.AZURE_CLUSTER_NAME }} --query "name" --output tsv >/dev/null 2>&1; then
            echo "âœ… AKS cluster ${{ env.AZURE_CLUSTER_NAME }} already exists"
            CLUSTER_STATE=$(az aks show --resource-group ${{ env.AZURE_RESOURCE_GROUP }} --name ${{ env.AZURE_CLUSTER_NAME }} --query "provisioningState" --output tsv)
            echo "Cluster state: $CLUSTER_STATE"
            if [ "$CLUSTER_STATE" != "Succeeded" ]; then
              echo "âš ï¸  Warning: Cluster is not in Succeeded state"
            fi
          else
            echo "AKS cluster ${{ env.AZURE_CLUSTER_NAME }} not found. Creating..."
            az aks create \
              --resource-group ${{ env.AZURE_RESOURCE_GROUP }} \
              --name ${{ env.AZURE_CLUSTER_NAME }} \
              --node-count 1 \
              --enable-addons monitoring \
              --enable-managed-identity \
              --enable-oidc-issuer \
              --enable-workload-identity \
              --network-plugin azure \
              --dns-service-ip 10.2.0.10 \
              --service-cidr 10.2.0.0/24 \
              --location eastus \
              --generate-ssh-keys \
              --attach-acr ${{ env.ACR_NAME }}
            echo "âœ… AKS cluster created successfully"
          fi

      - name: Get AKS credentials
        uses: azure/aks-set-context@v3
        with:
          resource-group: ${{ env.AZURE_RESOURCE_GROUP }}
          cluster-name: ${{ env.AZURE_CLUSTER_NAME }}

      - name: Validate Required CLI Tools
        run: |
          set -e

          echo "Validating required CLI tools (az, kubectl, jq)..."

          missing=0
          for cmd in az kubectl jq; do
            if ! command -v "$cmd" >/dev/null 2>&1; then
              echo "Error: required CLI tool '$cmd' is not installed or not in PATH"
              missing=1
            else
              echo "Found $cmd: $(command -v "$cmd")"
            fi
          done

          if [ "$missing" -ne 0 ]; then
            echo "One or more required CLI tools are missing. Failing before deployment."
            exit 1
          fi

      - name: Configure Key Vault RBAC for AKS
        continue-on-error: true
        run: |
          set -e
          KV_NAME="${{ secrets.AZURE_KEY_VAULT_NAME }}"
          if [ -z "$KV_NAME" ]; then
            echo "Key Vault name not set, skipping RBAC configuration"
            exit 0
          fi
          KV_ID=$(az keyvault show -g ${{ env.AZURE_RESOURCE_GROUP }} -n "$KV_NAME" --query id -o tsv 2>/dev/null || echo "")
          if [ -z "$KV_ID" ]; then
            echo "Key Vault not found, skipping RBAC configuration"
            exit 0
          fi
          AKS_MI_ID=$(az aks show -g ${{ env.AZURE_RESOURCE_GROUP }} -n ${{ env.AZURE_CLUSTER_NAME }} --query identityProfile.kubeletidentity.objectId -o tsv 2>/dev/null || echo "")
          if [ -z "$AKS_MI_ID" ]; then
            AKS_MI_ID=$(az aks show -g ${{ env.AZURE_RESOURCE_GROUP }} -n ${{ env.AZURE_CLUSTER_NAME }} --query identity.principalId -o tsv 2>/dev/null || echo "")
          fi
          if [ -z "$AKS_MI_ID" ]; then
            echo "AKS managed identity not found, skipping RBAC configuration"
            exit 0
          fi
          echo "AKS Managed Identity Object ID: $AKS_MI_ID"

          ROLE="Key Vault Secrets User"
          COUNT=$(az role assignment list --assignee-object-id "$AKS_MI_ID" --scope "$KV_ID" --query "[?roleDefinitionName=='$ROLE'] | length(@)" -o tsv 2>/dev/null || echo "0")

          if [ "$COUNT" = "0" ] || [ -z "$COUNT" ]; then
            echo "Attempting to assign Key Vault RBAC role..."
            # Use --assignee-object-id and --assignee-principal-type to avoid Graph API lookup
            if az role assignment create \
              --assignee-object-id "$AKS_MI_ID" \
              --assignee-principal-type "ServicePrincipal" \
              --role "$ROLE" \
              --scope "$KV_ID" 2>&1; then
              echo "âœ… Successfully assigned Key Vault RBAC role"
            else
              echo "âš ï¸  WARNING: Could not assign Key Vault RBAC role (insufficient permissions)"
              echo "    This may be okay if using Kubernetes secrets instead of Key Vault CSI"
              echo "    To fix manually, grant 'Key Vault Secrets User' role to: $AKS_MI_ID"
              exit 0
            fi
          else
            echo "âœ… Key Vault RBAC role already assigned"
          fi

      - name: Ensure Namespace Exists
        run: |
          kubectl create namespace cloudtolocalllm --dry-run=client -o yaml | kubectl apply -f -
      - name: Setup Azure Key Vault and Secrets Store CSI Driver
        run: |
          set -e
          # Install the Secrets Store CSI Driver and Azure Provider
          helm repo add secrets-store-csi-driver https://kubernetes-sigs.github.io/secrets-store-csi-driver/charts 2>/dev/null || true
          helm repo add csi-secrets-store-provider-azure https://azure.github.io/secrets-store-csi-driver-provider-azure/charts 2>/dev/null || true
          helm repo update

          # Check if CSI driver is already installed and healthy
          if helm status csi-secrets-store -n kube-system >/dev/null 2>&1; then
            HELM_STATUS=$(helm status csi-secrets-store -n kube-system -o json | jq -r '.info.status' 2>/dev/null || echo "unknown")
            if [ "$HELM_STATUS" = "deployed" ]; then
              echo "âœ… CSI Secret Store driver is already deployed and healthy"
              echo "Skipping installation"
              exit 0
            else
              echo "âš ï¸  CSI Secret Store driver exists but status is: $HELM_STATUS"
              echo "Will attempt to fix..."
            fi
          else
            echo "CSI Secret Store driver not found, will install"
          fi

          # Function to check and clear Helm locks
          clear_helm_locks() {
            local release_name="$1"
            local namespace="$2"
            
            echo "Checking for Helm locks for release: $release_name in namespace: $namespace"
            
            # Check if release exists and is in pending state
            local release_status=$(helm status "$release_name" -n "$namespace" 2>&1 || echo "not_found")
            if echo "$release_status" | grep -q "pending"; then
              echo "âš ï¸  Found pending Helm release, attempting to clear..."
              # Try to rollback to clear the pending state
              helm rollback "$release_name" -n "$namespace" 2>/dev/null || true
              sleep 5
            fi
            
            # Check for stuck releases and delete them if needed
            local stuck_release=$(helm list -n "$namespace" --pending 2>/dev/null | grep "$release_name" || echo "")
            if [ -n "$stuck_release" ]; then
              echo "âš ï¸  Found stuck Helm release, attempting to uninstall..."
              helm uninstall "$release_name" -n "$namespace" --ignore-not-found || true
              sleep 5
            fi
          }

          # Clear any existing locks for csi-secrets-store
          clear_helm_locks "csi-secrets-store" "kube-system"

          # Wait for any concurrent operations to complete
          echo "Waiting for any concurrent Helm operations to complete..."
          MAX_WAIT=120
          WAITED=0
          while [ $WAITED -lt $MAX_WAIT ]; do
            if ! helm list -n kube-system --pending 2>/dev/null | grep -q "csi-secrets-store"; then
              echo "âœ… No pending operations detected"
              break
            fi
            echo "Still waiting for pending operations... (${WAITED}s/${MAX_WAIT}s)"
            sleep 5
            WAITED=$((WAITED + 5))
          done

          if [ $WAITED -ge $MAX_WAIT ]; then
            echo "âš ï¸  Timeout waiting for pending operations, attempting to force clear..."
            helm uninstall csi-secrets-store -n kube-system --ignore-not-found || true
            sleep 10
          fi

          # Install/upgrade with retry logic
          RETRIES=5
          for i in $(seq 1 $RETRIES); do
            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
            echo "Attempt $i/$RETRIES: Installing CSI Secret Store driver..."
            echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
            
            # Clear locks before each attempt
            if [ $i -gt 1 ]; then
              clear_helm_locks "csi-secrets-store" "kube-system"
              sleep 10
            fi
            
            if helm upgrade --install csi-secrets-store \
              secrets-store-csi-driver/secrets-store-csi-driver \
              --namespace kube-system \
              --set "providers.azure.enabled=true" \
              --wait \
              --timeout 10m \
              --atomic; then
              echo "âœ… CSI Secret Store driver installed successfully"
              break
            else
              local exit_code=$?
              echo "âš ï¸  Attempt $i failed with exit code: $exit_code"
              
              if [ $i -lt $RETRIES ]; then
                echo "Waiting 15s before retry..."
                sleep 15
              else
                echo "âŒ Failed after $RETRIES attempts"
                echo "Checking release status..."
                helm status csi-secrets-store -n kube-system || true
                helm list -n kube-system || true
                exit 1
              fi
            fi
          done

      - name: Create SecretProviderClass
        run: |
          cat <<EOF | kubectl apply -f -
          apiVersion: secrets-store.csi.x-k8s.io/v1
          kind: SecretProviderClass
          metadata:
            name: azure-kvname-user-msi
            namespace: cloudtolocalllm
          spec:
            provider: azure
            parameters:
              usePodIdentity: "false"
              useVMManagedIdentity: "true"
              userAssignedIdentityID: "" # Set this to the client ID of the user-assigned managed identity if you use one.
              keyvaultName: ${{ secrets.AZURE_KEY_VAULT_NAME }}
              objects:  |
                array:
                  - |
                    objectName: POSTGRES-PASSWORD
                    objectType: secret
                  - |
                    objectName: JWT-SECRET
                    objectType: secret
                  - |
                    objectName: STRIPE-TEST-SECRET-KEY
                    objectType: secret
                  - |
                    objectName: CLOUDFLARE-TUNNEL-TOKEN
                    objectType: secret
              tenantId: ${{ secrets.AZURE_TENANT_ID }}
          EOF

      - name: Validate Required Secrets
        env:
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
          JWT_SECRET: ${{ secrets.JWT_SECRET }}
          STRIPE_TEST_SECRET_KEY: ${{ secrets.STRIPE_TEST_SECRET_KEY }}
          SENTRY_DSN: ${{ secrets.SENTRY_DSN }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_TUNNEL_TOKEN: ${{ secrets.CLOUDFLARE_TUNNEL_TOKEN }}
          SUPABASE_JWT_SECRET: ${{ secrets.SUPABASE_JWT_SECRET }}
        run: |
          missing=0
          check_secret() {
            name="$1"
            value="$2"
            if [ -z "$value" ]; then
              echo "Error: required secret $name is empty or not set"
              missing=1
            fi
          }

          check_secret POSTGRES_PASSWORD "$POSTGRES_PASSWORD"
          check_secret JWT_SECRET "$JWT_SECRET"
          check_secret STRIPE_TEST_SECRET_KEY "$STRIPE_TEST_SECRET_KEY"
          check_secret SENTRY_DSN "$SENTRY_DSN"
          check_secret CLOUDFLARE_API_TOKEN "$CLOUDFLARE_API_TOKEN"
          check_secret CLOUDFLARE_TUNNEL_TOKEN "$CLOUDFLARE_TUNNEL_TOKEN"
          check_secret SUPABASE_JWT_SECRET "$SUPABASE_JWT_SECRET"

          if [ "$missing" -ne 0 ]; then
            echo "One or more required secrets are missing. Failing before deployment."
            exit 1
          fi

      - name: Seed Azure Key Vault from secrets
        env:
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
          JWT_SECRET: ${{ secrets.JWT_SECRET }}
          STRIPE_TEST_SECRET_KEY: ${{ secrets.STRIPE_TEST_SECRET_KEY }}
          CLOUDFLARE_TUNNEL_TOKEN: ${{ secrets.CLOUDFLARE_TUNNEL_TOKEN }}
          SUPABASE_JWT_SECRET: ${{ secrets.SUPABASE_JWT_SECRET }}
        run: |
          set -e
          KV_NAME="${{ secrets.AZURE_KEY_VAULT_NAME }}"
          if [ -z "$KV_NAME" ]; then
            exit 0
          fi
          ensure_kv_secret() {
            local name="$1"
            local value="$2"
            if [ -z "$value" ]; then
              return
            fi
            if az keyvault secret show --vault-name "$KV_NAME" --name "$name" >/dev/null 2>&1; then
              return
            fi
            az keyvault secret set --vault-name "$KV_NAME" --name "$name" --value "$value" >/dev/null
          }
          ensure_kv_secret POSTGRES-PASSWORD "$POSTGRES_PASSWORD"
          ensure_kv_secret JWT-SECRET "$JWT_SECRET"
          ensure_kv_secret STRIPE-TEST-SECRET-KEY "$STRIPE_TEST_SECRET_KEY"
          ensure_kv_secret CLOUDFLARE-TUNNEL-TOKEN "$CLOUDFLARE_TUNNEL_TOKEN"
          ensure_kv_secret SUPABASE-JWT-SECRET "$SUPABASE_JWT_SECRET"

      - name: Create/Update Key Vault Secrets
        env:
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
          JWT_SECRET: ${{ secrets.JWT_SECRET }}
          STRIPE_TEST_SECRET_KEY: ${{ secrets.STRIPE_TEST_SECRET_KEY }}
          CLOUDFLARE_TUNNEL_TOKEN: ${{ secrets.CLOUDFLARE_TUNNEL_TOKEN }}
          SUPABASE_JWT_SECRET: ${{ secrets.SUPABASE_JWT_SECRET }}
        run: |
          # Only update Key Vault. K8s secrets should ideally be synced via External Secrets or managed by ArgoCD.
          # For now, we omit kubectl apply for secrets as it conflicts with GitOps state.
          echo "Updating Key Vault secrets..."

      - name: Update and Push Manifests (GitOps)
        env:
          POSTGRES_BUILT: ${{ needs.changes.outputs.postgres }}
          WEB_BUILT: ${{ needs.changes.outputs.web }}
          API_BUILT: ${{ needs.changes.outputs.api }}
          PROXY_BUILT: ${{ needs.changes.outputs.proxy }}
          APP_VERSION: ${{ needs.extract_version.outputs.app_version }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -e

          # 1. Determine tags
          [ "$POSTGRES_BUILT" = "true" ] && POSTGRES_TAG="${APP_VERSION}-postgres" || POSTGRES_TAG="latest"
          [ "$WEB_BUILT" = "true" ] && WEB_TAG="${APP_VERSION}" || WEB_TAG="latest"
          [ "$API_BUILT" = "true" ] && API_TAG="${APP_VERSION}-api" || API_TAG="latest"
          [ "$PROXY_BUILT" = "true" ] && PROXY_TAG="${APP_VERSION}-proxy" || PROXY_TAG="latest"

          # 2. Update Kustomize
          cd k8s/overlays/managed
          kustomize edit set image cloudtolocalllm/postgres=${{ needs.setup_acr.outputs.login_server }}/postgres:${POSTGRES_TAG}
          kustomize edit set image cloudtolocalllm/web=${{ needs.setup_acr.outputs.login_server }}/web:${WEB_TAG}
          kustomize edit set image cloudtolocalllm/api-backend=${{ needs.setup_acr.outputs.login_server }}/api-backend:${API_TAG}
          kustomize edit set image cloudtolocalllm/streaming-proxy=${{ needs.setup_acr.outputs.login_server }}/streaming-proxy:${PROXY_TAG}
          cd ../../..

          # 3. Commit and Push back to main
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add k8s/overlays/managed/kustomization.yaml

          # Check if there are changes to commit
          if git diff --staged --quiet; then
            echo "No manifest changes detected."
          else
            git commit -m "chore(ops): update manifests for v$APP_VERSION [skip ci]"
            git push origin main
            echo "âœ… Manifests updated and pushed. ArgoCD will reclaim the state."
          fi

      - name: Purge Cloudflare Cache
        continue-on-error: true
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          set -e

          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "Purging Cloudflare Cache"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

          # Get Zone ID for cloudtolocalllm.online (using scoped API token)
          DOMAIN="cloudtolocalllm.online"
          echo "Fetching Zone ID for: $DOMAIN"

          ZONE_RESPONSE=$(curl -s -X GET "https://api.cloudflare.com/client/v4/zones?name=$DOMAIN" \
            -H "Authorization: Bearer ${CLOUDFLARE_API_TOKEN}" \
            -H "Content-Type: application/json")

          ZONE_ID=$(echo "$ZONE_RESPONSE" | grep -o '"id":"[^"]*"' | head -1 | cut -d'"' -f4)

          if [ -z "$ZONE_ID" ]; then
            echo "âŒ Failed to get Zone ID"
            echo "Response: $ZONE_RESPONSE"
            exit 1
          fi

          echo "âœ… Zone ID: $ZONE_ID"
          echo "âœ… Using scoped API token (Zone Read + Cache Purge permissions only)"
          echo ""

          # Purge everything for the zone (covers all subdomains)
          echo "Purging cache for entire zone (all domains)..."

          RESPONSE=$(curl -s -X POST \
            "https://api.cloudflare.com/client/v4/zones/${ZONE_ID}/purge_cache" \
            -H "Authorization: Bearer ${CLOUDFLARE_API_TOKEN}" \
            -H "Content-Type: application/json" \
            --data '{"purge_everything": true}')

          # Check if successful (note the space after colon in Cloudflare's response)
          if echo "$RESPONSE" | grep -q '"success": true'; then
            echo "âœ… Cache purged successfully for all domains:"
            echo "   - cloudtolocalllm.online"
            echo "   - app.cloudtolocalllm.online"
            echo "   - api.cloudtolocalllm.online"
            echo ""
            echo "âœ… Users will now receive the latest deployed version"
          else
            echo "âš ï¸  Cache purge failed - deployment will continue"
            echo "Response: $RESPONSE"
            echo ""
            echo "To fix this, update your Cloudflare API token permissions:"
            echo "1. Go to https://dash.cloudflare.com/profile/api-tokens"
            echo "2. Edit your API token"
            echo "3. Add permission: Zone > Cache Purge > Purge"
            echo "4. Update GitHub secret: gh secret set CLOUDFLARE_API_TOKEN"
            echo ""
            echo "For now, users may see cached content until it expires or they hard refresh (Ctrl+Shift+R)"
          fi

      - name: Deployment Initiated
        run: |
          echo "âœ… Manifests promoted to Git."
          echo "ğŸš€ ArgoCD will now reconcile the cluster state."

      - name: Deployment Summary
        if: success()
        run: |
          echo "Deployment to Azure AKS completed successfully."
          echo "Cluster: ${{ env.AZURE_CLUSTER_NAME }} (resource group: ${{ env.AZURE_RESOURCE_GROUP }})"
          echo "Namespace: cloudtolocalllm"
          echo "Images pulled from registry: ${{ env.DOCKER_REGISTRY }}"
          echo "Public endpoints:"
          echo "  - App:  https://app.cloudtolocalllm.online/"
          echo "  - API:  https://api.cloudtolocalllm.online/"
